---
title: 'A Seriously Slow Fibonacci Function'
author: Oran Looney
date: 2019-07-04
tags:
  - Python
  - Math
image: /post/slow-fibonacci_files/lead.jpg
draft: true
---



<p>I recently wrote <a href="http://www.oranlooney.com/post/fibonacci/">an article</a> which was ostensibly about the Fibonacci function but was really about optimization techniques. I wanted to follow up on its (extremely moderate) success by going in the exact opposite direction: by making the Fibonacci function as <strong>slow</strong> as possible. This is not as easy as it sounds: any program can <em>trivially</em> be made slower, but this is boring. How can we make it slow in a fair and interesting way? The answer is to use a <a href="https://en.wikipedia.org/wiki/Model_of_computation">model of computation</a> which was not <em>deliberately</em> designed to be slow but which in practice is quite slow because it was designed for simplicity.</p>
<p>While there are <a href="https://en.wikipedia.org/wiki/Turing_machine">several</a> models of computation to <a href="https://en.wikipedia.org/wiki/%CE%9C-recursive_function">choose</a> from, I selected the <a href="https://en.wikipedia.org/wiki/Lambda_calculus">lambda calculus</a> as being particularly easy to write an spectacularly inefficient implementation in.</p>
<p>Some of you no doubt will be having flashbacks at the mention of the name, while others have already started slowly edging their mouse towards the close tab icon. But don’t worry - if you done any programming before you’ve already seen all the “hard” ideas associated with it and what’s left is a “toy” language that can be learned in a few minutes. By the end of this article you will see clearly how you could write your own non-trivial programs directly in the lambda calculus.</p>
<p>In fact, the problem with the lambda calculus is that it is <em>too</em> simple: it is difficult at first to see how anyone could <em>do</em> anything with it. Luckily for us, there exists a set of macros which turn the lambda calculus into a much higher level language. They were developed by <a href="https://en.wikipedia.org/wiki/Alonzo_Church">Alonzo Church</a>, the inventor/discoverer of the lambda calculus, in parallel with the lambda calculus itself. These macros provide a simple and concrete way of encoding numbers, mathematical operators, boolean logic, and even data structures like lists, maps, and trees. Today, this technique is called <a href="https://en.wikipedia.org/wiki/Church_encoding">Church encoding</a>. If lambda calculus is machine code, then the <a href="https://en.wikipedia.org/wiki/Church_encoding">Church encoding</a> is more like C or LISP.</p>
<div id="goal" class="section level2">
<h2>Goal</h2>
<p>David Allen says to begin with the goal in mind, so let’s take a look at what we’re shooting for. Here is a performance-naive implementation of a function which finds the <span class="math inline">\(n\)</span>-th Fibonacci number, implemented in vanilla <a href="https://www.python.org/">Python</a>:</p>
<pre><code>def fibonacci(n):
    if n &lt;= 1:
        return n
    else:
        return naive_fib(n-1) + naive_fib(n-2)</code></pre>
<p>Let’s put together a grocery list of every type and operations needed in order to implement this function:</p>
<ol style="list-style-type: decimal">
<li>natural numbers</li>
<li>addition</li>
<li>subtraction</li>
<li>less than comparison</li>
<li>if/else branch</li>
<li>recursion</li>
</ol>
<p>Well, we certainly have our work cut out for us, don’t we? The first four require a <a href="https://en.wikipedia.org/wiki/Peano_axioms#Models">model of the Peano axioms</a>, the if/else branch requires a model of <a href="https://en.wikipedia.org/wiki/Boolean_algebra">Boolean algebra</a>, and <a href="https://www.google.com/search?q=recursion">recursion</a> is usually regarded as a non-trivial language feature.</p>
<p>Before any of that, though, we need an implementation of the lambda calculus itself. For the purposes of this article, we’re going to take a non-standard approach and not use the original notation. Instead, we’ll use a <em>subset</em> of Python which has a one-to-one correspondence with the lambda calculus but which is hopefully both more familiar and more accessible to readers: all of the code in this article will run in any Python 3 interpreter so readers can follow along and try their own experiments if they like. I shall call this the “Pythonic” lambda calculus when I want to specifically refer to the lambda calculus implemented as a subset of the Python grammar.</p>
<p>In the next section I will describe this subset more formally and describe how it maps to the lambda calculus. In this section, I’ll do a quick high-level overview and give an example of where we are going.</p>
<p>Python already has the two main operations we need anonymous lambda functions (<code>lambda x: x</code>) and function application (<code>f(x)</code>) so this is perfectly natural.</p>
<p>In addition, we will implement features by introducing <em>definitions</em>, which are basically macros with a human readable name that expand out to lambda calculus expressions. Here is an example of a definition:</p>
<pre><code>plus = lambda m: lambda n: lambda f: lambda x: m(f)(n(f)(x))</code></pre>
<p>Definitions get substituted into other expressions very much like running “Find and Replace All” in an IDE or</p>
<pre><code>s/plus/(lambda m: lambda n: lambda f: lambda x: m(f)(n(f)(x)))/g</code></pre>
<p>in VI or sed. By introducing definitions, we will incrementally build up a surprisingly high-level and expressive language.</p>
<p>This is good time to exhibit what the Fibonacci function will look like in the Pythonic lambda calculus when we’re done.</p>
<pre><code>fibonacci = Y(lambda f: PIR(
    # define function f(n) as:
    lambda n: (
        # if n &lt; 2
        less_than(n)(two))
            # then n
            (n)
            # else f(n-1) + f(n-2)
            (plus
                (f(minus(n)(one)))
                (f(minus(n)(two))))))</code></pre>
<p>As always in Python, <code>#</code> indicates an non-executable comment. It shouldn’t be to hard to see the basic shape of the familiar, friendly Fibonacci function in there. If you have any LISP, it will even look vaguely familiar, although the parentheses are in slightly different places. (In LISP, function application looks like <code>(minus n 2)</code> instead of <code>minus(n)(two)</code>.)</p>
<p>In the next section, we will briefly describe the lambda calculus and the Pythonic variant we will be using.</p>
</div>
<div id="lambda-calculus-in-python" class="section level2">
<h2>Lambda Calculus in Python</h2>
<p>In the lambda calculus, there are only two operations, abstraction and application. These two can be composed to write any program (computable function) that has or ever will be written. (Since the lambda calculus is <a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing complete</a>, this can be interpreted as implying that all computation can be reduced to abstraction and application; all else is vanity and grasping at wind.)</p>
<p>What do we mean by the term “abstraction?” Let’s say we have a concrete calculation, such as the sums of squares of a vector like <code>(3, 4)</code>. We could type the following into a Python interpreter:</p>
<pre><code>3*3 + 4*4</code></pre>
<p>In an interactive programming session, this might suffice: you type something in and hit ENTER to see the answer. In most cases values <code>3</code> and <code>4</code> are too hard-coded to be useful. So we can <em>abstract</em> this by replacing <code>3</code> with a placeholder variable <code>x</code> and introducing a function of <code>x</code>:</p>
<pre><code>def half_ss(x):
    return x*x + 4*4</code></pre>
<p>Now that we have an abstraction, a.k.a. a <em>function</em>, how do we use it? Before we can do any concrete computation, we need to know what <code>x</code> is supposed to be. This is called <em>function application</em> or simply <em>application</em>, and we use the familiar <code>f(x)</code> syntax common to math and almost all programming languages.</p>
<pre><code>half_ss(3)</code></pre>
<p>But this “half” function isn’t very satisfactory. The <code>4</code> is still hard coded.</p>
<p>If we want to do the same thing again and abstract <code>4</code> into <code>y</code>, we have a couple of choices. We <em>could</em> greatly complicate our language and add another syntactic primitive <code>,</code>:</p>
<pre><code>def half_ss(x, y):
    return x*x + y*y

ss(3, 4)</code></pre>
<p>But if we want to keep things simple, why don’t we simply perform abstraction twice?</p>
<pre><code>def ss(x):
    def half_ss(y):
        return x*x + y*y
    return half_ss</code></pre>
<p>Note that when we call <code>ss(3)</code>, what is returned is again a function, so we can use a second application to pass the second argument:</p>
<pre><code>ss(3)(4)</code></pre>
<p>The two applications “cancel out” the two abstractions, and we are left with the concrete value <code>3*3 + 4*4</code>, more commonly known as 25.</p>
<p>This works because we call norm with the first argument and instead of resolving to a value, it instead returns a function that we can call with the second argument to get the result. We can repeat this operation as many times as necessary, but it get’s inconvenient to make up a silly name like <code>half_norm</code> each time; instead we’ll use an <em>anonymous</em> lambda function:</p>
<pre><code>ss = lambda x: lambda y: x*x + y*y

ss(3)(4)</code></pre>
<p>So to recap, we implement the abstraction operation of lambda calculus in Python by using a <code>lambda</code> expressions with a single argument each, and if we want to define a function that takes more than one argument we stack up lambda expressions like <code>lambda x: lambda y: lambda z :...</code> .</p>
<p>Note that we can write our entire program without recourse to any names if we treat <code>ss</code> as a definition and replace the string <code>ss</code> with its right-hand side where ever it appears. The final program is:</p>
<pre><code>(lambda x: lambda y: x*x + y*y)(3)(4)</code></pre>
<p>Which you can run and verify that it gives the answer 25.</p>
<p>In the lambda calculus, application is the <em>only</em> way we can do <em>anything</em>, so we should re-write the binary expressions as more primitive functions:</p>
<pre><code>(lambda x: lambda y: sqrt(plus(mult(x)(x))(mult(y)(y))))(3)(4)</code></pre>
<p>Now, you may well complain that the operation I’ve called “application” shows the <em>syntax</em> that says a function should be called with a certain argument, but I haven’t said anything about how this function call should actually be carried out!</p>
<p>TODO: this is the job of the computer (human, machine or otherwise)</p>
<p>It turns out this is exactly the reverse of abstraction - we replace abstract variables with concrete values. This is called the <span class="math inline">\(\beta\)</span>-reduction rule (read “beta reduction”.) For example, we may call the function <code>lambda x: x(x)(x)</code> with concrete value <code>t</code> by writing <code>(lambda x: x(x)(x))(t)</code>. The <span class="math inline">\(\beta\)</span>-reduction rules allows us to remove the <code>lambda x</code> and go through and replace every <code>x</code> in the body of the function with <code>t</code>, which leaves us with <code>t(t)(t)</code>. Since <code>t</code> is a free variable, we cannot reduce this any further, so we stop. Let’s do the same thing to our norm example:</p>
<pre><code>(lambda x: lambda y: plus(mult(x)(x))(mult(y)(y)))(3)(4)

(lambda y: plus(mult(3)(3))(mult(y)(y)))(4)

plus(mult(3)(3))(mult(4)(4))</code></pre>
<p>Since <code>plus</code>, <code>mult</code>, and even <code>3</code> and <code>4</code> are just definitions, we could expand those definitions and continue the beta-reduction process until only a single concrete value remains. Below, we will study the Church encoding for natural numbers and learn exactly how to do this.</p>
<p>So abstraction introduces lambda expressions, application tells us when we should call a function and which argument to pass in, and <span class="math inline">\(\beta\)</span>-reduction tells us how to carry out that function call.</p>
<p>There is one other rule, called <span class="math inline">\(\alpha\)</span>-replacement (read “alpha replacement”), which tells us that we can change the variable names of functions whenever we want, as long as we are consistent and change it everywhere inside the body of the function too while also avoiding conflicts with other variable names. For example, these two lambda expressions are the same, and we can use the <span class="math inline">\(\alpha\)</span>-replacement rule to transform one into the other and vice versa:</p>
<pre><code>lambda x: x
lambda y: y</code></pre>
<p>The lambda expression <code>lambda x: y</code> on the other hand, would not be the same the two above, because we cannot replace <code>x</code> with <code>y</code> without a conflict. We could change <code>lambda x: y</code> into <code>lambda z: y</code>, but that would be a different function. This rule should be intuitively obvious. It’s also not particularly important because we equally well could have <a href="https://en.wikipedia.org/wiki/De_Bruijn_index">used an infinite sequence of variable names</a> to avoid conflicts; this would completely eliminate the need for the <span class="math inline">\(\alpha\)</span>-replacement rule. The <span class="math inline">\(\beta\)</span>-reduction rule captures the very essence of what it means to carry out a computation; the <span class="math inline">\(\alpha\)</span>-replacement rule is book-keeping.</p>
<p>The above gives the <em>flavor</em> of the lambda calculus: abstraction, application, <span class="math inline">\(\alpha\)</span>-replacement and <span class="math inline">\(\beta\)</span>-reduction.</p>
<p>But the examples I’ve used have share the weakness that if you go far enough down, you are relying on operations other than these two. For example, <code>mult = lambda x: lambda y: x * y</code>. This is a serious defect, because the whole point of the lambda calculus is to prove that these two operations suffice to define <em>any</em> computable function.</p>
<p>To correct this defect, we need to start from scratch and scrupulously avoid using any operation <em>except</em> for abstraction and application. This will lead us to types and data structures very different than the native python <code>int</code> and <code>bool</code> but we nevertheless will be able to compute with them.</p>
</div>
<div id="grammar" class="section level2">
<h2>Grammar</h2>
<p>In Python, these rules are equivalent to:</p>
<pre><code>&lt;lambda-expression&gt; ::= &lt;variable&gt;
                      | &quot;(&quot; lambda &lt;var&gt; &quot;:&quot; &lt;lambda-expression&gt; &quot;)&quot;
                      | &lt;lambda-expression&gt; &quot;(&quot; &lt;lambda-expression&gt; &quot;)&quot;</code></pre>
<p>In some cases, where it causes no ambiguity, we will omit the parentheses around lambda functions. Note that the <em>placement</em> of parentheses is rather different than in the original lambda calculus syntax! Hopefully, this notation for function application will be familiar to those of you who have studied modern high level programming languages or pure mathematics. It should also be fairly obvious how to translate from one the other:</p>
<pre><code>lambda x: lambda y: x(x(y))</code></pre>
<p><span class="math display">\[ \lambda x . \lambda y . (x (x y)) \]</span></p>
<p>As a convenience, we will also allow ourselves <em>definitions</em>, although we will later show that these definitions are merely a convenience and can be done away with whenever we choose through the simple process of string substitution. (The development of the Church encoding proceeds mainly by means of such definitions.) A definition looks like this:</p>
<pre><code>&lt;definition&gt; ::= &lt;definition-name&gt; &quot;=&quot; &lt;lambda-expression&gt;</code></pre>
<p>Where the <lambda-expression> on the right is restrictions to have no free variables. That is to say, every variable used is in fact inside the body of a lambda function with that variable as a parameter. For example, <code>lambda x: x(x)(x(x))</code> has no free variables, but <code>lambda x: y(x)</code> has <code>y</code> as a free variable. Furthermore, while definitions can contain other definitions, they cannot ever contain themselves, not even implicitly hidden away in some other definition. Otherwise, the simple string substitution macro expansion of a definition would never terminate! (Later, when we need recursion to implement the Fibonacci function, we will need to find a way to do this!)</p>
<p>These restrictions exist so that we can think of our extended grammar as nothing more than a set of lightweight macros on top of lambda calculus. In principle, for any given program written in the extended grammar, we can simply substitute in the body of the definition wherever we find the name of the definition. This takes only a finite number of steps and is guaranteed to terminate. At the end of this process, we are left with an equivalent program in the original lambda calculus, with no definitions or definition names. Furthermore, we can complete this “macro preprocessing” step entirely before beginning to run the program.</p>
<p>The full extended grammar looks like this:</p>
<pre><code>&lt;definition&gt; ::= &lt;definition-name&gt; &quot;=&quot; &lt;lambda-expression&gt;

&lt;lambda-expression&gt; ::= &lt;variable&gt;
                      | &quot;(&quot; lambda &lt;var&gt; &quot;:&quot; &lt;lambda-expression&gt; &quot;)&quot;
                      | &lt;lambda-expression&gt; &quot;(&quot; &lt;lambda-expression&gt; &quot;)&quot;
                      | &quot;(&quot; &lt;definition-name&gt; &quot;)&quot;</code></pre>
<p>Both the original grammar and the extended grammar are strict subsets of Python, and as such is runnable on a Python interpreter. This is, perhaps, the most extreme example of programming “into” a language instead of programming “in” a language, following <a href="https://codeblog.jonskeet.uk/2008/04/23/programming-quot-in-quot-a-language-vs-programming-quot-into-quot-a-language/">McConnell’s distinction.</a></p>
<p>Note that if we run an expression in the extended grammar directly in Python, the interpreter does <em>not</em> do the macro expansions as described above… but the results of the calculations will always be identical if we’ve carefully followed the rules for introducing definitions! Later, we will show examples of running programs both ways.</p>
<p>Incidentally, by exhibiting a model of the lambda calculus in Python, we’ve shown that Python is Turing complete, although to complete the proof we would need to show that Python’s execution of these lambda expressions is equivalent to the <span class="math inline">\(\beta\)</span>-reduction rule. However this would take us far afield of our main purpose, which is to exhibit a practical, runnable example of a non-trivial program written entirely in the lambda calculus.</p>
</div>
<div id="church-booleans" class="section level2">
<h2>Church Booleans</h2>
<pre><code># Church Booleans
true =  lambda x: lambda y: x
false = lambda x: lambda y: y</code></pre>
<p>Note that these are <strong>not</strong> the same as Python’s built-in <code>True</code> and <code>False</code> constants.</p>
<p>Some may object that these are not <em>values</em>, these are <em>functions</em>. Of course they are; the lambda calculus is made out of nothing <em>but</em> functions! But that doesn’t prevent us from thinking of some functions as values when it is convenient for us. Consider the objects of object-oriented programming - an object is nothing but a collection of functions called “methods,” but we usually think of objects as values.</p>
<p>More generally, it is often convenient to talk about the “type” of different lambda expressions. However, because we are technically working in the “untyped” lambda calculus, we will have to keep the concept of “type” high-level and informal for now. (I’ll have more to say about types when we discuss recursion.)</p>
<p>Since we are keeping things informal, we can use an intuitive definition: the type of a lambda calculus expression is roughly the number and types of the parameter it would normally be called with. In high level languages this is often called the function signature. The two Church Booleans we defined both have the same type - they expect to be called with two arguments and will then return one or the other of those two arguments unchanged.</p>
<p>Consider the following function, which takes a Boolean argument:</p>
<pre><code>lambda p: p(ifvalue)(elsevalue)</code></pre>
<p>It will “work” equally well if <code>p</code> is <code>true</code> or <code>false</code> - only the behavior will be different. If <code>p</code> is <code>true</code>, it will return the <code>ifvalue</code> and if <code>p</code> if <code>false</code> it will return the <code>elsevalue</code>… in other words, it has the exact same semantics as a typical if/else statement!</p>
<p>In general, if we have a predicate (an expression which evaluates to a Boolean), we can always write an if/else statement like:</p>
<pre><code>((&lt;predicate&gt;)
    (&lt;if-expression&gt;)
    (&lt;else-expression&gt;))</code></pre>
<p>While we will have to wait until after we’ve defined the Church numbers to get really useful predicates like <code>less_than</code>, we can go ahead and define the usual Boolean operators purely in terms of our above definitions for <code>true</code> and <code>false</code>:</p>
<pre><code># Boolean logic
AND = lambda x: lambda y: x(y)(false)
OR  = lambda x: lambda y: x(true)(y)
NOT = lambda x: x(false)(true)
XOR = lambda x: lambda y: x(NOT(y))(y)</code></pre>
<p>Each of these expects to be passed Boolean values and then returns a single Boolean value. We can unpack these using the above equivalence to <code>if/else</code>; for example, <code>AND</code> reads as “if x is true, then return y, else return false”. This will return true only if <code>x</code> and <code>y</code> are both <code>true</code>, so this function acts like “and”. You can read the other definitions in the same way.</p>
<p>To more easily interface with these functions, let’s write a bridge:</p>
<pre><code>def church_to_bool(b: Callable) -&gt; bool:
    return b(True)(False)

def bool_to_church(b: bool) -&gt; Callable:
    return true if b else false</code></pre>
<p>Now that we have these bridge functions, it’s fairly easy to write a test demonstrating that we’ve correctly implemented the truth tables for each of Boolean operation:</p>
<pre><code>for x in (True, False):
    for y in (True, False):
        x_c = bool_to_church(x)
        y_c = bool_to_church(y)
        z_c = AND(x_c)(y_c)
        z = church_to_bool(z_c)
        print(x, &quot;AND&quot;, y, &quot;=&quot;, z)

True AND True = True
True AND False = False
False AND True = False
False AND False = False</code></pre>
<p>At this point I encourage you to try to test some of the other Boolean operators, and to write your own, such as <code>NAND</code> or the <code>SUM</code> and <code>CARRY</code> of a <a href="https://en.wikipedia.org/wiki/Adder_(electronics)#Full_adder">full adder</a> for more of a challenge.</p>
<p>This has been our first taste of computing the lambda calculus. The pattern, which we’ll see much more of, is simple: use Church encoding to somehow translate your input values into lambda expressions. Pass those into a lambda expression which represent your program; then reverse the Church encoding to recover meaningful values.</p>
</div>
<div id="church-numerals" class="section level2">
<h2>Church Numerals</h2>
<p>The Church encoding of the natural numbers, called Church numerals, defines the number <span class="math inline">\(n\)</span> to be a binary (taking two arguments) function which takes a function <code>f</code> and an arbitrary value <code>x</code> and applies <code>f</code> to <code>x</code> exactly <span class="math inline">\(n\)</span> times:</p>
<pre><code>zero = lambda f: lambda x: x
one = lambda f: lambda x: f(x)
two = lambda f: lambda x: f(f(x))
three = lambda f: lambda x: f(f(f(x)))
# ... and so on</code></pre>
<p>How do you apply a function zero times? Well, you don’t; you just return the value <code>x</code> right away. To call it once is <code>f(x)</code>, twice is <code>f(f(x))</code>, and so on. This means that Church numbers are <strong>not</strong> an arbitrary sequence of symbols that only gain semantics because of the relations defined on them (as they are in <a href="https://en.wikipedia.org/wiki/Set-theoretic_definition_of_natural_numbers">other models</a>) but actually have behavior which is directly related to their meaning: the <span class="math inline">\(n\)</span>-th Church number has the behavior of repeating a computation <span class="math inline">\(n\)</span> times.</p>
<p>For example, suppose we have a function called <code>print</code> and a message <code>&quot;Hello, Lambda Calculus!&quot;</code> and we want to print this message 3 times. How would we implement something like that in the lambda calculus? Just so:</p>
<pre><code>&gt; three(print)(&quot;Hello, Lambda Calculus!&quot;)
Hello, Lambda Calculus!
Hello, Lambda Calculus!
Hello, Lambda Calculus!</code></pre>
<p>Of all the high level programming languages I know, I think only Ruby <a href="https://ruby-doc.org/core-2.5.0/Integer.html#method-i-times">comes close</a> to the idea that numbers should literally be their own for loops. Even LISP and Haskell require recursion, a separate <a href="http://zvon.org/other/haskell/Outputprelude/map_f.html">map</a> function, or a <a href="http://cl-cookbook.sourceforge.net/loop.html">loop macro</a> to achieve this. (For code readability alone this is probably a good thing, though.)</p>
<p>This one-to-one correspondence between Church numerals and behaviors makes it relatively easy to define mathematical operations on Church numbers. Following Peano, the first thing we need is a successor function which can increment a number by one:</p>
<pre><code>succ = lambda n: lambda f: lambda x: f(n(f)(x))</code></pre>
<p>Why does this work? Well, given an original number <code>n</code>, it first <em>uses</em> <code>n</code> to apply <code>f</code> to <code>x</code> <span class="math inline">\(n\)</span> times. It then applies <code>f</code> once more itself. Thus, the final value will be <code>f</code> applied to <code>x</code> <span class="math inline">\(n+1\)</span> times, which is <span class="math inline">\(n+1\)</span> by definition.</p>
<p>This successor function allows us to easily construct new numbers <em>ad infinitum</em>:</p>
<pre><code># 0-10 for convenience
zero = lambda f: lambda x: x
one = lambda f: lambda x: f(x)
two = succ(one)
three = succ(two)
four = succ(three)
five = succ(four)
six = succ(five)
seven = succ(six)
eight = succ(seven)
nine = succ(eight)
ten = succ(nine)

church_digits = [zero, one, two, three, four, five, six, seven, eight, nine]</code></pre>
<p>We can now define other mathematical operators:</p>
<pre><code># church numerals
plus = lambda m: lambda n: lambda f: lambda x: m(f)(n(f)(x))
mult = lambda m: lambda n: lambda f: lambda x: m(n(f))(x)
exp = lambda m: lambda n: n(m)
pred = (lambda n: 
            lambda f: lambda x: 
                n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u))
minus = lambda m: lambda n: n(pred)(m)</code></pre>
<p>Of these, <code>plus</code> and <code>mult</code> are the easiest to understand. <code>plus</code> applies <code>f</code> to <code>x</code> first <span class="math inline">\(m\)</span> times, then applies <code>f</code> to the result <span class="math inline">\(n\)</span> times, for a total of <span class="math inline">\(n+m\)</span>. The multiplication operator <code>mult</code> looks very similar, but does things in a slightly different order: it <em>first</em> defines a new function <code>g = n(f)</code> which applies <code>f</code> to some value n times, and <em>then</em> applies <code>g</code> to <code>x</code> m times. Since each call to <code>g</code> ends up calling <code>f</code> <span class="math inline">\(n\)</span> times, the result is that <code>f</code> is applied to <code>x</code> <span class="math inline">\(m \times n\)</span> times.</p>
<p>Try to figure out <code>exp</code> for yourself. It’s equivalent to <span class="math inline">\(m^n\)</span>. It’s not on the main line of functionality we need for the Fibonacci function, and it’s very clever!</p>
<p><code>pred</code> is the predecessor relation. It subtracts one from a number if possible. (Zero is just mapped to zero, as negative numbers are not defined.) It’s more complex than <code>succ</code> but studying it is extremely rewarding, because it leads to understanding how data structures can be represented in the lambda calculus. The basic idea is that we are going to but the value <code>x</code> in a box and replace <code>f</code> with a different function, which I’ll call <code>skip_first</code>. The first time <code>skip_first</code> is called, it sees that the box has not been opened, so it opens that. After that, it sees that the box is already open, so it takes the value out of the box, applies <code>f</code> to it once, and puts it back in the box. It does this <span class="math inline">\(n\)</span> times. At the end, it takes the value of the box. The ultimate result is that <code>f</code> is applied to <code>x</code> <span class="math inline">\(n-1\)</span> times, because nothing happened the first time. In this analogy, the initial closed “box” is <code>lambda u: x</code>, the new box that is created after each step is <code>lambda h: h(g(f))</code>, and the <code>lambda u: u</code> at the end is the final act of taking the value out of the box.</p>
<p><code>pred</code> is not trivial to understand, especially in this elementary form. I’ve given it my best shot, and the Wikipedia article makes a <a href="https://en.wikipedia.org/wiki/Church_encoding#Derivation_of_predecessor_function">valiant effort</a> too. If it gives you trouble, I suggest you leave it aside and study the rest of theory until you learn how to encode the “pair” data structure. Then <code>pred</code> much may be defined in a much more natural way. The only reason I am not doing that here is because I introducing pairs or lists TODO just to implement the Fibonacci function so decided to take the straight path through the mud. Nevertheless, there is a switchback trail with a very gentle slope right <a href="https://en.wikipedia.org/wiki/Cons">over there</a>.</p>
<p>Defining <code>pred</code> was the hard part. The definition of <code>minus</code> in terms of <code>pred</code> is much easier: <code>n</code> applies the function <code>pred</code> to <code>m</code> <span class="math inline">\(n\)</span> times, so we subtract one <span class="math inline">\(n\)</span> times, which is the same as subtracting <code>n</code> from <code>m</code>.</p>
<p>Now that we have a reasonable set of mathematical operations, let’s do some practical examples. We can do basic operations like <span class="math inline">\(2+2\)</span> or <span class="math inline">\(6 \times 7\)</span>:</p>
<pre><code>plus(two)(two)
mult(six)(seven)</code></pre>
<p>The problem with these is that what they return is a Church numeral, which is a Python <a href="https://stackoverflow.com/questions/111234/what-is-a-callable">Callable</a>. All I see on my screen when I run the above snippets is an opaque and ambiguous output like this:</p>
<pre><code>&lt;function __main__.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;(x)&gt;</code></pre>
<p>To translate this back into something we can understand, we need to write a bridge function. How can we “unpack” a Church number? Recall that the Church encoding of <span class="math inline">\(n\)</span> is a function taking two arguments, a function <span class="math inline">\(f\)</span> and a value <span class="math inline">\(x\)</span>, and it applies <span class="math inline">\(f\)</span> to <span class="math inline">\(x\)</span> <span class="math inline">\(n\)</span> times: <span class="math inline">\(f^n(x)\)</span>. In our Python environment, this works even if <span class="math inline">\(x\)</span> and <span class="math inline">\(f\)</span> are not written in the lambda calculus! This means we can write a very simple function to translate Church numbers into native Python <code>int</code>s:</p>
<pre><code>def church_to_int(n: Callable) -&gt; int:
    return n(lambda x: x+1)(0)</code></pre>
<p>Going the other way requires no such tricks. If I want to encode the number 42 in the lambda calculus, I can use the first ten digits (defined above) and our mathematical operations to build up the Church number:</p>
<pre><code>plus(mult(four)(ten))(two)</code></pre>
<p>We can use the same strategy for any number. All we really need to do is parse the base 10 representation of a number and build up the Church number in stages:</p>
<pre><code>def int_to_church(n: int) -&gt; Callable:
    church_number = church_digits[ int(str(n)[0]) ]
    for digit in str(n)[1:]:
        church_digit = church_digits[int(digit)]
        church_number = plus(mult(church_number)(ten))(church_digit)
    return church_number</code></pre>
<p>We can now perform non-trivial calculations entirely in the lambda calculus:</p>
<pre><code>&gt; print(&quot;2 + 2 =&quot;, church_to_int(plus(two)(two)))
4

&gt; print(&quot;6 * 7 =&quot;, church_to_int(mult(six)(seven)))
42</code></pre>
<p>Here is a much larger (and slower) example:</p>
<pre><code>&gt; a = int_to_church(1001)
&gt; b = int_to_church(999)
&gt; ab = mult(a)(b)
&gt; print(&quot;1001 * 999 =&quot;, church_to_int(ab))
999999</code></pre>
<p>Now, finally, we can implement our sums-of-squares method:</p>
<pre><code>&gt; a = int_to_church(3)
&gt; b = int_to_church(4)
&gt; ss = plus(exp(a)(two))(exp(b)(two))
&gt; print(&quot;3**2 + 4**2 =&quot;, church_to_int(ss))
25</code></pre>
<p>This isn’t all of number theory of course, but its enough to implement our little Fibonacci function (and it turns out that</p>
</div>
<div id="predicates-involving-numbers" class="section level2">
<h2>Predicates Involving Numbers</h2>
<p>The first and most basic predict test we need is a check for zero. This will form the foundation of all the other predicates:</p>
<pre><code>is_zero = lambda n: n(lambda x: false)(true)</code></pre>
<p>This works because if <code>lambda x: false</code> is called even once, the result will be <code>false</code>, and this can only be avoided if the function is never called, in which case the original value <code>true</code> will be returned. But the only Church numeral which <em>never</em> calls its function argument is <code>zero</code>, so the above function returns <code>true</code> only for <code>zero</code>, and <code>false</code> for every other number.</p>
<p>By the way, a function which returns a value of type Church Boolean is the <em>definition</em> of a “predicate” in this context. The word carries no logical or semantic content here.</p>
<p>Because <code>pred</code> stops at zero and <code>pred(zero) == zero</code> then <code>minus(x)(y) == zero</code> if and only if <code>y</code> is bigger than or equal to <code>x</code>. We can use this fact to define various comparison tests:</p>
<pre><code>leq = lambda m: lambda n: is_zero(minus(m)(n))
less_than = lambda m: lambda n: leq(succ(m))(n)
eq = lambda m: lambda n: AND(leq(m)(n))(leq(n)(m))</code></pre>
<p>These functions are interesting because while the expect their arguments <code>n</code> and <code>m</code> to be Church numbers, their return value is a Church Boolean. The main thing we wanted was <code>less_than</code>, which we will need for our Fibonacci function.</p>
<p>As a curious aside, let’s also compare the definitions for <code>false</code> and <code>zero</code>:</p>
<pre><code>zero = lambda f: lambda x: x
false = lambda x: lambda y: y</code></pre>
<p>By the <span class="math inline">\(\alpha\)</span>-replacement rule, we can see that these two functions are actually identical: Just like in C, <code>zero</code> <em>is</em> <code>false</code> in the Church encoding! However, we cannot make too much of this: non-zero numbers are not really equivalent to <code>true</code> so we do always need to use a type-conversion function like <code>is_zero</code> if we want to treat a number as a Boolean. Furthermore, this is in some sense just a coincidence; we could have instead defined <code>true</code> to return the second argument and <code>false</code> to return the first and still built an entirely workable Boolean algebra.</p>
</div>
<div id="recursion" class="section level2">
<h2>Recursion</h2>
<p>Rather than jumping straight into implementing recursion in the lambda calculus, let’s take it slow and develop the idea in stages. Let’s start with vanilla Python recursion:</p>
<pre><code>def factorial(n):
    if n &lt;= 1:
        return 1
    else:
        return n * factorial(n-1)</code></pre>
<p>This only works because by the time the interpreter reaches the statement <code>factorial(n-1)</code> the global symbol table already contains an entry for <code>factorial</code>, so Python happily resolves <code>factorial</code> to that function and calls it. In other words, it works because Python is doing all the heavy lifting for us!</p>
<p>In the lambda calculus, there is no global symbol table. Even if there were, lambda functions are all anonymous: they don’t have names, so what would you even query the symbol table for? The workaround is to pass the function into itself as an argument. This is totally legal; for example, <code>x(x)</code> is a perfectly cromulent expression in Pythonic lambda calculus. Continuing with our factorial example a little further, we have:</p>
<pre><code>def _factorial(f, n):
    if n &lt;= 1:
        return 1
    else:
        return n * f(f, n-1)

def factorial(n):
    return _factorial(_factorial, n)</code></pre>
<p>Neat. But it’s a little ugly that we have to make the recursive call as <code>f(f, n-1)</code> and explicitly pass <code>f</code> back into itself. Why not make <code>f</code> a closure which <a href="https://en.wikipedia.org/wiki/Currying">Currys</a> that first argument for us?</p>
<pre><code>def _factorial(f, n):
    if n &lt;= 1:
        return 1
    else:
        return n * f(n-1)

def factorial(n):
    f = lambda m: _factorial(f, m)
    return f(n)</code></pre>
<p>We can make this more generic and reduce reliance on the global namespace by passing <code>_factorial</code> in as an argument:</p>
<pre><code>def call_recursively(g, n):
    f = lambda m: g(g, m)
    return f(n)

def _factorial(f, n):
    if n &lt;= 1:
        return 1
    else:
        return n * f(n-1)

def factorial(n):
    call_recursively(_factorial, n)</code></pre>
<p>Finally, the <code>call_recursively</code> function can be abstracted entirely as a Python decorator. (If you’re not familiar with the decorator syntax, <code>@decorator/f</code> is simply syntactic sugar for <code>f = decorator(f)</code> and is a convenient way to apply a functor to a function.)</p>
<pre><code>def recursive(f):
    def recursive(n):
        g = lambda m: f(f, m)
        return g(n)
    return recursive

@recursive
def factorial(f, n):
    if n &lt;= 1:
        return 1
    else:
        return n * f(n-1)
    </code></pre>
<p>So, in vanilla Python, we’ve implemented a reusable utility which enables us to conveniently do recursion that allows us to avoid any reference to the global symbol table. We can translate this half-way into Pythonic lambda calculus simply by refactoring every named function into a lambda function:</p>
<pre><code>recursive = lambda f: lambda n: (lambda m: f(f, m))(n)

@recursive
def factorial(f, n):
    if n &lt;= 1:
        return 1
    else:
        return n * f(n-1)</code></pre>
<p>The above still uses a function of two arguments and the factorial function is still written in vanilla Python. As we make the jump to the final form purely in Pythonic lambda calculus, we will rename <code>recursive</code> to <code>Y</code> - it is indeed the famous Y-combinator, the higher-order function which makes recursion (and therefore also iteration) possible in the lambda calculus. As for <em>why</em> it is called <code>Y</code>, I have no idea - it’s just the <a href="https://en.wikipedia.org/wiki/Lambda_calculus#Standard_terms">standard symbol</a>.</p>
<pre><code>Y = lambda f: (lambda x: x(x))(lambda y: f(lambda z: y(y)(z)))</code></pre>
<p>We can also apply exactly one application of the <span class="math inline">\(\beta\)</span>-reduction rule to bring this into an equivalent symmetrical form:</p>
<pre><code>Y = lambda f: (lambda y: f(lambda z: y(y)(z)))(lambda y: f(lambda z: y(y)(z)))</code></pre>
<p>While the symmetrical form is more often seen, I prefer the first version because I think it more clearly expresses the idea of currying a function with itself. However, both do exactly the same thing. Furthermore, neither have any free variables and so meet our requirements for a proper definition.</p>
<p>In an ideal world we could now define the recursive factorial function entirely in Pythonic lambda calculus like so:</p>
<pre><code>factorial = Y(lambda f: PIR(
    lambda n:
        ((leq)(n)(one)
            (one)
            (mult(n)(f(pred(n)))))))</code></pre>
<p>However, there is a problem: when we run the above function we get a stack overflow error. Why this so? Is the algorithm wrong? No: if you executed this lambda expression with true <span class="math inline">\(\beta\)</span>-reduction, it would work fine. The problem is that our Church Boolean pseudo-<code>if-else</code> statement is not quite the same as <code>if-else</code> other languages. If we use <code>if-else</code> in a language like C or Python, the code inside the selected branch will be executed, but code in the other branch will <em>not even be run.</em> However, in the Pythonic lambda calculus, if we write:</p>
<pre><code>((some-predicate)
    (if-branch)
    (else-branch))</code></pre>
<p>Then <em>both</em> the <code>if-brach</code> and the <code>else-brach</code> will need to be evaluated completely regardless of the value of <code>some-predicate</code>. This is called “eager” evaluation and Python <em>always</em> eagerly evaluates all arguments of a function call. Therefore in Python, we will always compute <em>both</em> branches, and only at the very end will we discard one of the values. Normally, this wouldn’t cause serious problems because the answer would always be the same (it would just be a little slower) but it becomes a serious problem in the case of recursion because the <code>else</code> branch is <em>always</em> evaluated, which calls the function again, which calls the function again, and so for forever.</p>
<p>One response would be to give up on Python and go abuse some other language which has lazy evaluation TODO. Alternatively, we could write an interpreter for the lambda calculus which implements <span class="math inline">\(\beta\)</span>-reduction rule, side-stepping Python entirely.</p>
<p>TODO</p>
<pre><code># cheap hack because I can&#39;t get true and false to short circuit.
def PIR(f):
    def wrapper_function(n):
        if church_to_bool(is_zero(n)):
            return zero
        else:
            return f(n)
    return wrapper_function</code></pre>
<p>With our little hack in place, we can now implement a working version of the factorial function which does not cause a stack overflow:</p>
<pre><code>factorial = Y(lambda f: PIR(
    lambda n:
        ((leq)(n)(one)
            (one)
            (mult(n)(f(pred(n)))))))</code></pre>
<p>Long stacks of parentheses appear to be an operational hazard when working with <span class="math inline">\(\lambda\)</span>-calculus inspired languages.</p>
<p><a href="https://xkcd.com/297/"> <img 
    alt="cartoon where parentheses are described as 'elegant weapons for a more... civilized age.'"
    src="https://imgs.xkcd.com/comics/lisp_cycles.png"> </a></p>
<p>In any case, the above function is a little inconvenient to call because it requires a Church numeral as input and returns an opaque Church numeral, so we will wrap it with bridge code:</p>
<pre><code>def slow_factorial(n):
    n = int_to_church(n)
    fac = factorial(n)
    return church_to_int(fac)</code></pre>
<p>This little function correctly computes factorials:</p>
<pre><code>for n in range(1, 10):
    print(n, slow_factorial(n))

1  1
2  2
3  6
4  24
5  120
6  720
7  5040
8  40320
9  362880
10 3628800</code></pre>
<p>However, it is <em>extremely</em> slow: it takes over a minute to calculate <span class="math inline">\(10!\)</span> on a fairly new laptop. That works out to <em>36 million times slower</em> than the vanilla Python implementation.</p>
<p>We can profile the code to figure out why. Here, I’ve edited the profiler output from <code>%prun slow_factorial(9)</code> to give names to the most common calls; in the original the function name was always just <code>(&lt;lambda&gt;)</code> distinguished only by line number.</p>
<pre><code>   ncalls  tottime  percall  cumtime  percall function
  1564014    0.849    0.000    0.849    0.000 succ
   362889    0.354    0.000    0.542    0.000 plus
   362880    0.188    0.000    0.188    0.000 church_to_int
   260669    0.152    0.000    0.152    0.000 zero
    79211    0.052    0.000    0.052    0.000 pred
      9/1    0.000    0.000    0.003    0.003 factorial</code></pre>
<p>So, we actually spend almost all of our time simply incrementing numbers by one. Church numbers are easy to define and work with, but they are gloriously inefficient, especially as the numbers grow. A more efficient encoding could be defined by using the Boolean algebra we developed earlier to define operations on binary strings, but that is not what we are about today.</p>
<p>TODO types</p>
</div>
<div id="final-fibonacci" class="section level2">
<h2>Final Fibonacci</h2>
<p>We now have all the necessary tools. All that remains is to implement the Fibonacci algorithm.</p>
<pre><code>fibonacci = Y(lambda f: PIR(
    lambda n: 
        less_than(n)(two)
            (n)
            (plus
                (f(minus(n)(one)))
                (f(minus(n)(two))))))</code></pre>
<p>As before, we’ll wrap this in bridge code to handle the translation between native Python integers and Church numerals:</p>
<pre><code>def slow_fibonacci(n: int) -&gt; int:
    n = int_to_church(n)
    fib = fibonacci(n)
    return church_to_int(fib)</code></pre>
<p>We can test that it is correct by exhibiting the Fibonacci numbers up through <span class="math inline">\(F_20\)</span>:</p>
<pre><code>for n in range(21):
    print(n, slow_fibonacci(n))

0 0
1 1
2 1
3 2
4 3
5 5
6 8
7 13
8 21
9 34
10 55
11 89
12 144
13 233
14 377
15 610
16 987
17 1597
18 2584
19 4181
20 6765</code></pre>
</div>
<div id="how-slow-is-slow" class="section level2">
<h2>How Slow is Slow?</h2>
<p>As expected, this is rather slow, over 6 seconds to calculate <span class="math inline">\(F_20\)</span>:</p>
<pre><code>%time slow_fibonacci(20)

CPU times: user 6.59 s, sys: 20 ms, total: 6.61 s
Wall time: 6.6 s</code></pre>
<p>This is one thousand times as slow as the same naive algorithm in vanilla Python, and about a million times slower than a good algorithm. Note however that this is still faster than a human could work it out on paper! As recently as 80 years ago this would have been state-of-the-art.</p>
<p>A straight line on a log-scale plot shows that the algorithm scales as <span class="math inline">\(\mathcal{O}(2^n)\)</span>.</p>
<div class="figure">
<img src="/post/slow-fibonacci_files/timing_slow_fib.png" title="A log-scale plot of time to compute then n-th Fibonacci function with the slow_fibonacci function." alt="Timing Slow Fibonacci" />
<p class="caption">Timing Slow Fibonacci</p>
</div>
<p>The profiler shows where we were spending our time:</p>
<pre><code>   1922492 function calls (1833945 primitive calls) in 1.858 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall function
  1133885    0.513    0.000    0.513    0.000 pred
  17710/1    0.199    0.000   31.615   31.615 fibonacci
    95316    0.173    0.000    3.507    0.000 two
    59896    0.159    0.000    3.636    0.000 mult
    53131    0.118    0.000   30.497    0.001 is_zero
    53130    0.110    0.000    0.280    0.000 minus
  35421/1    0.092    0.000   31.615   31.615 PIR-wrapper
  35420/2    0.083    0.000   31.615   15.807 Y
   119792    0.074    0.000    0.074    0.000 three
    35421    0.072    0.000    0.114    0.000 church_to_bool
    17710    0.057    0.000   10.598    0.001 less_than
    35420    0.052    0.000    0.076    0.000 fibonacci-wrapper
    64077    0.041    0.000    0.041    0.000 zero
    35420    0.024    0.000    0.024    0.000 PIR
    17710    0.022    0.000    0.033    0.000 one
    28655    0.014    0.000    0.014    0.000 false
    24476    0.012    0.000    0.012    0.000 true
    17710    0.012    0.000    0.012    0.000 leq
    17711    0.012    0.000    0.012    0.000 plus
    17710    0.012    0.000    0.012    0.000 succ
     6765    0.006    0.000    0.006    0.000 church_to_int</code></pre>
<p>Unlike <code>slow_factorial()</code> which deals with numbers that blow up <a href="https://en.wiktionary.org/wiki/superexponential">very quickly</a>, <code>slow_factorial()</code> deals with relatively smaller numbers which means that we spent less time simply iterating through <code>succ</code> and more time doing interesting things. Nevertheless, it spends a <em>lot</em> of time doing simple subtractions - this is one of the weak points of the Church numerals.</p>
</div>
<div id="slower-than-slow" class="section level2">
<h2>Slower Than Slow</h2>
<p>How could we make this even <em>slower</em>? Again, in a fair way, not just sprinkling no-ops and sleep statements throughout.</p>
<p>One interesting approach would be to implement what is sometimes called a <a href="https://en.wikipedia.org/wiki/Meta-circular_evaluator">meta-circular evaluator</a>: an interpreter for the lambda calculus written entirely within the lambda calculus itself. We could then stack interpreters indefinitely, with each layer costing us another factor of a thousand. It would be reminiscent of this art project where a long gear chain is used to build a machine which will take 13.7 billion years for the final gear to complete one rotation. The machine has a electric motor happily whirring away at one end, and a solid block of concrete at the other; but because gear steps the revolution speed down by a factor of 20, the motion is infinitesimal after only a few steps.</p>
<p><a href="https://www.youtube.com/watch?v=Fqu4zm8v6aI"> <img src="/post/slow-fibonacci_files/slow_gears.jpg"> </a></p>
<p>We’re not actually going to do that, of course. This article is already way too long. But we <em>could.</em></p>
</div>
<div id="macro-expansion" class="section level2">
<h2>Macro Expansion</h2>
<p>Perhaps you don’t believe that this is really a lambda calculus program; after all, it has all those “definitions” which look suspiciously like named functions and in fact are being treated as named functions by the Python interpreter! Very suspicious.</p>
<p>I can show this is not the case by doing a search-and-replace for each name and replacing it with its body, and repeating that until nothing is left. Below is the step-by-step working out, with one version per line; the last line contains no definitions (expect our <code>PIR</code> hack) and instead is composed entirely of <code>lambda</code> functions, function calls, and bound variable names.</p>
<pre><code>fibonacci = Y(lambda f: PIR(lambda n: (less_than(m)(two))(n)(two)(n)(plus(f(minus(n)(one)))(f(minus(n)(two))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: leq(succ(m))(n))(n)(two)(n)(plus(f(minus(n)(one)))(f(minus(n)(two))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: (lambda m: lambda n: is_zero(minus(m)(n)))(succ(m))(n))(n)(two)(n)(plus(f(minus(n)(one)))(f(minus(n)(two))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: (lambda m: lambda n: (lambda n: n(lambda x: false)(true))(minus(m)(n)))(succ(m))(n))(n)(two)(n)(plus(f(minus(n)(one)))(f(minus(n)(two))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: (lambda m: lambda n: (lambda n: n(lambda x: (lambda x: lambda y: y))(lambda x: lambda y: x))(minus(m)(n)))(succ(m))(n))(n)(two)(n)(plus(f(minus(n)(one)))(f(minus(n)(two))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: (lambda m: lambda n: (lambda n: n(lambda x: (lambda x: lambda y: y))(lambda x: lambda y: x))((lambda m: lambda n: n(pred)(m))(m)(n)))(succ(m))(n))(n)(two)(n)(plus(f((lambda m: lambda n: n(pred)(m))(n)(one)))(f((lambda m: lambda n: n(pred)(m))(n)(two))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: (lambda m: lambda n: (lambda n: n(lambda x: (lambda x: lambda y: y))(lambda x: lambda y: x))((lambda m: lambda n: n(pred)(m))(m)(n)))(succ(m))(n))(n)(two)(n)(plus(f((lambda m: lambda n: n(pred)(m))(n)(one)))(f((lambda m: lambda n: n(pred)(m))(n)(two))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: (lambda m: lambda n: (lambda n: n(lambda x: (lambda x: lambda y: y))(lambda x: lambda y: x))((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(m)(n)))(succ(m))(n))(n)(two)(n)(plus(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)(one)))(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)(two))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: (lambda m: lambda n: (lambda n: n(lambda x: (lambda x: lambda y: y))(lambda x: lambda y: x))((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(m)(n)))(succ(m))(n))(n)(two)(n)((lambda m: lambda n: lambda f: lambda x: m(f)(n(f)(x)))(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)(one)))(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)(two))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: (lambda m: lambda n: (lambda n: n(lambda x: (lambda x: lambda y: y))(lambda x: lambda y: x))((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(m)(n)))(succ(m))(n))(n)(succ(one))(n)((lambda m: lambda n: lambda f: lambda x: m(f)(n(f)(x)))(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)(lambda f: lambda x: f(x))))(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)(succ(one)))))))
fibonacci = Y(lambda f: PIR(lambda n: (lambda m: lambda n: (lambda m: lambda n: (lambda n: n(lambda x: (lambda x: lambda y: y))(lambda x: lambda y: x))((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(m)(n)))((lambda n: lambda f: lambda x: f(n(f)(x)))(m))(n))(n)((lambda n: lambda f: lambda x: f(n(f)(x)))(lambda f: lambda x: f(x)))(n)((lambda m: lambda n: lambda f: lambda x: m(f)(n(f)(x)))(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)(lambda f: lambda x: f(x))))(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)((lambda n: lambda f: lambda x: f(n(f)(x)))(lambda f: lambda x: f(x))))))))
fibonacci = (lambda f: (lambda x: x(x))(lambda y: f(lambda z: y(y)(z))))(lambda f: PIR(lambda n:(lambda m: lambda n: (lambda m: lambda n: (lambda n: n(lambda x: (lambda x: lambda y: y))(lambda x: lambda y: x))((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(m)(n)))((lambda n: lambda f: lambda x: f(n(f)(x)))(m))(n))(n)((lambda n: lambda f: lambda x: f(n(f)(x)))(lambda f: lambda x: f(x)))(n)((lambda m: lambda n: lambda f: lambda x: m(f)(n(f)(x)))(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)(lambda f: lambda x: f(x))))(f((lambda m: lambda n: n((lambda n: lambda f: lambda x: n(lambda g: lambda h: h(g(f)))(lambda u: x)(lambda u: u)))(m))(n)((lambda n: lambda f: lambda x: f(n(f)(x)))(lambda f: lambda x: f(x))))))))</code></pre>
<p>The ultimate expanded version of this function works just as well and is just as fast. Although it does nothing but create closures and call functions, somehow in the end it carries out the computation of a mathematical function. True, it is a <a href="https://en.wikipedia.org/wiki/Understatement">little hard to read</a> in this form, but so is machine code.</p>
<p>Here is a visualization of the full Fibonacci program (click for a larger image.) This shows every node (either a variable, function call, or lambda abstraction) as a binary tree.</p>
<p><a href="/post/slow-fibonacci_files/ast.png"> <img src="/post/slow-fibonacci_files/ast.png" title="Visualization of the Abstract Syntax Tree of the elementary Fibonacci function." alt="Fibonacci AST" /> </a></p>
<p>It reminds me a lot of this <a href="https://xkcd.com/224/">XKCD comic strip about LISP</a> where <a href="https://en.wikipedia.org/wiki/Cons"><code>cons</code></a> is taken as primitive. Of course, the <a href="https://en.wikipedia.org/wiki/Church_encoding#Church_pairs">pair data structure</a> can easily be defined in the lambda calculus as well.</p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>All models of computation are equal, but some are more equal than others. In theory, the lambda calculus is only a constant factor away from any other model of computation, but the same is not true for the Church encoding: Church numerals are useful because they are very easy to “bootstrap;” that is to say, to implement in terms of lower level primitives, while on the other hand it is very difficult to implement more efficient numbers without data structures and a ready supply of distinct symbols, which the Church numerals provide.</p>
<p>It took us only a few dozen definitions to go from something so spartan that it seemed to be missing every convenience of modern programming, to a useful language with recursion, for loops, if/else statements, and recursive function calls. Things like closures, Currying, functors/decorators, which are considered advanced features in other languages, we somehow got for free.</p>
<p>If we carried on defining signed numbers, pairs, lists, associative maps, and so on, this parsimony would continue and after a few hundred definitions - rather smaller than the standard library of most languages - we would have a perfectly functional language.</p>
<p>Some languages like <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)">Forth</a> and <a href="https://iolanguage.org/">io</a> in fact take this exact approach: the language is absolutely minimal and almost everything is moved to the standard library, including the definition of standard constructs like <code>for</code> and <code>if/else</code>.</p>
<p>If computation is so simple, why are modern languages so complicated? It mostly boils down to the <a href="https://devblogs.microsoft.com/oldnewthing/20180123-00/?p=97865">impedance mismatch</a> between the lambda calculus and the kinds of electronic computers we can actually build. We can’t actually just make an arbitrarily fast <span class="math inline">\(\beta\)</span>-reducer, but we <em>can</em> make a machine which can perform mathematical operations on two 64 bit numbers in a single cycle. For reasons that aren’t entirely clear, the lambda calculus has been a fruitful model for thinking about high-level, expressive ways of computing, while the Turing machine has been a fruitful model for how to design and actual computing machines. While in theory we can always switch from one model of computation to another, in practice this can involve a three or four order of magnitude reduction is performance. Practical programming languages have to walk the line between exposing the real capabilities of the machine while also providing useful high level abstractions. This turns out to be much harder than simply getting something that works at all in a performance naive way, which is basically what we’ve been doing in this article.</p>
<p>TODO:</p>
<p><a href="https://en.wikipedia.org/wiki/Lambda_calculus#%CE%B7-conversion">https://en.wikipedia.org/wiki/Lambda_calculus#%CE%B7-conversion</a></p>
<p><a href="https://stackoverflow.com/questions/10499514/y-combinator-discussion-in-the-little-schemer/11864862#11864862" class="uri">https://stackoverflow.com/questions/10499514/y-combinator-discussion-in-the-little-schemer/11864862#11864862</a></p>
<p>TODO: norm -&gt; sums-of-squares</p>
</div>
