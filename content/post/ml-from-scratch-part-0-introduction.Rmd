---
title: 'ML From Scratch, Part 0: Introduction'
author: "Oran Looney"
date: '2018-11-12'
slug: ml-from-scratch-part-0-introduction
tags:
  - Python
  - Statistics
  - From Scratch
  - Machine Learning
image: /post/ml-from-scratch-part-0-introduction_files/lead.jpg
draft: true
---

Motivation
----------

> "As an apprentice, every new magician must prove to his own satisfaction, at
> least once, that there is truly great power in magic." - The Flying Sorcerers,
> by David Gerrold and Larry Niven

How do you know if you really understand something? You *could* just rely on
the subjective experience of *feeling* like you understand. This sounds
plausible - surely you of all people should know. But this runs head-first into
in the [Dunning-Kruger effect][DK]. Introspection is not a reliable guide to
self-knowledge.

A different way is suggested by this pithy quote:

> "What I cannot create, I do not understand." - Richard Feynman

This is a very famous quote, but it's not entirely unambiguous.  If we're going
to use it as a guide, we'll first have to break it down a little.

The most common interpretation might be, "what I cannot explain to a layperson
or to a curious child, I do not understand." Feynman unambiguously valued the
ability to explain complex physics in plain English, as exemplified in this
anecdote:

> Before the commercial announcement of the Connection Machine CM-1 and all of
> our future products, Richard would give a sentence-by-sentence critique of
> the planned presentation. "Don't say 'reflected acoustic wave.' Say [echo]."
> Or, "Forget all that 'local minima' stuff. Just say there's a bubble caught
> in the crystal and you have to shake it out." Nothing made him angrier than
> making something simple sound complicated. - [Danny Hillis][RFCM]

[RFCM]: http://longnow.org/essays/richard-feynman-and-connection-machine/

As has often been remarked, explaining things well is often just as beneficial
to the teacher than the student; it helps reinforce ideas and built up
intuition.

If that is all that Feynman had meant, though, why use the term "create" at
all?  Surely "explain" or "teach" is closer to the meaning discussed above. So
while "explain in simple terms" is certainly *part* of it, "create" includes
more than just that. Feynman gives us a clue in this story from his
autobiography:

> "During the conference I was staying with my sister in Syracuse. I brought the
> paper home and said to her, "I can't understand these things that Lee and Yang
> are saying. It's all so complicated."
> 
> "No," she said, "what you mean is not that you can't understand it, but that
> you didn't invent it. You didn't figure it out your own way, from hearing the
> clue. What you should do is imagine you're a student again, and take this paper
> upstairs, read every line of it, and check the equations. Then you'll
> understand it very easily."
> 
> I took her advice, and checked through the whole thing, and found it to be very
> obvious and simple. I had been afraid to read it, thinking it was too
> difficult." - Richard Feynman, <i>Surely You're Joking, Mr. Feynman!</i>

So in the context of math or physics, "create" means something closer to
"derive from first principles by hand." This is a very strong criteria! If a
person could go into an empty office with a stack of scratch paper and supply
of sharp pencils, write down all first principles and proceed to derive every
important theorem in their chosen field by hand then it must be conceded
that such a person has some real knowledge.

In the context of computer science and programming, "create" might mean
something like, "write a program from scratch that implements the given
algorithm." Since machine learning straddles the two, "create" means both: pose
a machine learning problem mathematically, reduce the problem to some tractable
form on paper, then write and implement an algorithm to produce a numerical
approximation of the answer. 

Now, if someone attempts this exercise, one of two things will happen. First,
they may succeed completely on their first try. If so, great! They've proved
what they set out to prove. But a much more likely outcome is that they'll
succeed only partially and get stuck on several points. Well, now they have the
opportunity to correct a deficiency in their own understanding that they
weren't previously aware of, which is also a great outcome. After all, Feynman
didn't go in empty-handed - he took the challenging paper with him, and surely
referenced it often. But at the end, his own notes would record his own
complete derivation from start to finish and therefore serve as a testimonial
to his own understanding.

Ground Rules for the Project
----------------------------

It was in the spirit of the above considerations that in the fall of 2018 I set
myself a goal: I would, over the course of the next year, derive and implement
a representative sample of models and algorithms from machine learning,
entirely from scratch and (insofar as was possible) entirely from memory. Where
I found my understanding sufficient this would be an exercise in recreational
programming; where my understanding failed me it would be a chance to shore up
the foundations.

This is possibly less insane than it may appear. Although there are aspects of
machine learning that are [very][VC] technical, for the most part the
implementation of practical algorithms requires little more than some
moderately advanced statistics, quite a bit linear algebra, some familiarity
with numerical optimization and of course basic programming skills. While today
there are specialized degrees one could obtain, I've always felt that I was
well served by my physics degree in that regard. For example, physics
undergraduates are first exposed to the [method of Lagrange multipliers][LP] in
the context of classical mechanics where it is quite easy to understand. So
when the same method shows up in a much more abstract form in the study of
[SVMs][SVM] the learning curve isn't quite so vertical. I don't envy students
trying to understand the method for the first time in the context of an
implicit high-dimensional feature space!

Because an open-ended project like this has a tendency to get out of control,
I also decided to set some ground rules to help keep things sane.

First, mathematical derivations are in scope. This usually means posing and
solving an optimization problem of some form, such as [MLE.][MLE] This is
straight-forward for most of the algorithms on my list, but could get a little
hairy for things like backpropagation (which requires some fairly non-trivial
matrix calculus) or SVMs (which basically requires the entire theory of
[Quadradic Programming][QP].) In practice, the presentation of these
derivations is bottlenecked by the necessity of typesetting the equations
in $\LaTeX$ so these will typically little more than sketches of the proofs.

[MLE]: https://en.wikipedia.org/wiki/Maximum_likelihood_estimation
[QP]: https://en.wikipedia.org/wiki/Quadratic_programming

Second, the algorithms used will be state-of-the-art, or at least reasonably
so.  For example, while we *could* solve linear regression with gradient
descent, we're not going to punt like that. Instead, we'll do something closer
to what modern statistical software would do. This also means implementing
vectorized versions of the algorithms whenever possible: while iterating over
every example in the training set is often easier to understand, it's also
pretty far removed from the realities of modern implementations which rely
heavily on vectorization or even GPU acceleration for performance.

Third, I will implement and test all algorithms some data set. As the agile
crowd would say, working software is the primary measure of progress. For
convenience, I will use Python 3 and allow myself `numpy` arrays... but *not*
`numpy.linalg` or other high-level libraries like `scipy.optimize`; matrix
multiplication is about the most complex operation we'll let the libraries do
for us. (I considered not using `numpy` at all, but it allows us to express
algorithms in vectorized notation.) This restriction only applies to the
implementation of the algorithm itself and excepts tests - I will routinely use
higher-level libraries (like `pandas`, `scipy`, or `sklearn.datasets`) when
*testing* the algorithm.

Fourth and finally, I'll be publishing write-ups as I go. I've found in
practice this can be more time consuming than the original exercise, but
it attempting to explain each in simple terms to a broad audience should
help me come to understand them a little better as well.


Project Scope
-------------

While I want to touch on every aspect of machine learning, there's little point
in implementing minor variations of basically the same algorithms over and
over. Instead, let's pick one or two representative algorithms from each
category and leave it at that. We want to make sure that we get reasonable
coverage over the types of ML *problems* ( supervised/unsupervised,
regression/classification, etc.) as well as good coverage over the most
important *algorithms* that crop up repeatedly in ML. 

Here's the short list of candidates:

|Problem|Model|Algorithm|
|:-------------------------:|:-----------------------:|:-------------------------------:|
|Regression|Linear Regression| [QR Decomposition][QRD] |
|Classification|Logistic Regression| [Gradient Descent][GD] |
|Classification|Neural Network| [Backpropagation][BPA] |
|Classification|Decision Tree| [Recursive Partition][RPA] |
|Clustering| [Gaussian Mixture Model][GMM] | [EM Algorithm][EMA] |
|Clustering|Hierarchical Clustering| [Agglomerative Clustering][ACA] |
|Dimension Reduction| [Principal Component Analysis][PCA] | [QR Algorithm][QRA] |
|Recommendation| [Low-Rank Matrix Approximation][LRA] | [Alternating Projections][APA] |
|Regression|General Additive Models| [Backfitting][BFA] |
|Classification|Support Vector Machines| [SMO Algorithm][SMO] |

[PCA]: https://en.wikipedia.org/wiki/Principal_component_analysis
[GMM]: https://en.wikipedia.org/wiki/Mixture_model#Multivariate_Gaussian_mixture_model

[GD]: https://en.wikipedia.org/wiki/Gradient_descent
[SMO]: https://en.wikipedia.org/wiki/Sequential_minimal_optimization
[QRA]: https://en.wikipedia.org/wiki/QR_algorithm
[ACA]: https://en.wikipedia.org/wiki/Hierarchical_clustering
[BFA]: https://en.wikipedia.org/wiki/Backfitting_algorithm
[EMA]: https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm
[RPA]: https://en.wikipedia.org/wiki/Recursive_partitioning
[BPA]: https://en.wikipedia.org/wiki/Backpropagation
[QRD]: https://en.wikipedia.org/wiki/QR_decomposition
[LRA]: https://en.wikipedia.org/wiki/Low-rank_approximation
[APA]: https://en.wikipedia.org/wiki/Low-rank_approximation#Alternating_projections_algorithm

Other candidates I considered but ultimately decided were out-of-scope:

* [Factor Analysis][FA] - We already have PCA for dimensional reduction and GMM
  as an example of using the EM algorithm to solve for latent random variables.
* K-Means - We'll do GMM instead.
* [K-Nearest Neighbors][KNN] - A naive algorithm is trivial while a serious
  algorithm would mostly be implementing a spatial index (such as
  [R-Trees][RT]) which takes us pretty far afield from learning algorithms.
* Ensemble models - e.g. Random Forest or Boosted Trees. Not a good fit for the
  "from scratch" approach and can best be understood as "composing" two or more
  other mature models.
* [CNN, RNN, etc.][NNZ] - We'll do the vanilla deep neural network from scratch
  but more advanced topologies are best explored with a framework with
  automated differentiation. 
* [Learning-to-Rank][LTR] - e.g. [Bradley-Terry-Luce][BTL], [Rasch model][RM],
  etc. These can generally be reduced to logistic regression or viewed as
  latent variable models and solved with the EM algorithm.
* Felligi-Sunter Record Linkage - another take on the EM algorithm.

How can a Machine Learn?
------------------------

In the spirit of the Feynman technique, let's spend a few minutes talking
through the problem in plain English before we dive into the math.

The problem, in the broadest possible terms, is to get a computer to learn how
to do something. This is in contract to traditional programming, where the
computer does not usually "learn" anything, but follow a program written by a
human programmer. Computers also aren't very good at "doing" most things,
although they are very good (and very fast!) at the few things they *can* do. 

So, what *are* computers good at? In decreasing order (increasing by the amount
of time it takes) computers can do the following:

1. Addition and subtraction      
2. Multiplication 
3. Division
4. Comparing two numbers to decide what to do next
5. Other math functions like `exp()`, `log()`, `sin()`, `cos()`, etc.
5. Remembering a billion numbers
6. Looking something up in a file or database
7. Talking to another computer over a network

This fairly standard set of relative costs actually leads directly to some
important insights that guide research into practical machine learning.  While
we could just have the computer "memorize" a bunch of examples by storing them
in a database, that's actually quite slow relative to arithmetic.
[Instance-based learning algorithms][IBL] do exist but they tend too bog down
on too much data, which algorithms based mostly on arithmetic
actually do better and better when given more data. 

[IBL]: https://en.wikipedia.org/wiki/Instance-based_learning

1. Any "learning" that a computer does will have to be in the form of
   remembering a set of numbers.
2. The "doing" will work best if it is mostly additions and multiplications,
   with an occasional division or comparison.

Setting aside learning for a second, let's talk about "doing". Let's say we've
"remembered" some numbers $a$, $b$, $c$, and $d$.  These numbers are called our
"parameters." How would we use this to do something? Specifically, how do we
turn a set of numbers into a decision?  Let's say we want to drive a car. We
can "do" this by returning a number $y$ which represents which direction we
want to turn the wheel and how far. To make this decision, we can use a LIDAR
system to check for obstacles in three directions: straight ahead, 30&#176; to
the left, and 30&#176; to the right. Let's call those $x_l$, $x_s$, and $x_r$.
These numbers are zero or very low if it's clear in that direction, and 1 or
close to 1 if there's a close obstacle in that direction. A 0.5 would represent
an obstacle that's still some distance away.  How can we use the operations
that computers are best at to get this computer to make a decision about how to
turn the wheel? One way would be to use a linear equation:

\[ y = a x_l + b x_s + c x_s + d \]

Now, a human could come up with rules that would work passably. Say, if an
obstacle is to the left, steer right. If an obstacle is to the right, steer
left. If an obstacle is straight ahead, hard right. That would represent
parameters

\[ a=10 \; b=100 \; c=-10 \; d = 0 \]

This rule isn't terrible, but it would be better if we took a hard *left*
instead of a hard *right* when straight ahead was blocked but there was also
something to the right. How would we express that rule with just addition
and multiplication? One way would be to add a new term to our equation
(along with another parameter $e$) which was the *product* of $x_r$ and
$x_s$. This term will be large only when both $x_r$ AND $x_s$ are large.

\[ y = a x_l + b x_s + c x_s + d + e x_s x_r \]

Something fairly magical is starting to happen: our equation is starting
to model *logic*. Not every complicated logic yet, but it points the
way to much more complicated things.

But the idea is not to have a human come up with rules and "code" them as
parameters - the idea is to get the computer to figure out new parameters
for itself. However this intermediate idea of merely having the computer
learn a set of number (parameters) which it can then turn into decisions
via some equation that can combines both the parameters and data - this
already greatly simplifies the problem. Maybe I wasn't sure how to get
the program to "learn" a program, but I'm certain I can get a computer
to remember a set of numbers.

Not just remember - it actually has to come up with those parameters.  Good
parameters - parameters that *work.* Unfortunately the computer won't have any
idea what "works" unless we tell it; we're going to need some kind of feedback
which tells it if its getting closer. 

Essentially, we play a game of Hot or Cold with the computer. At each step it
changes its parameters; We tell it it's now "warmer" or "colder" and how hot it
is in absolute terms. If it usually explores in the "warmer" direction and
keeps going until its found a "very hot" spot, it's very likely to be able to
win the game. If we define "hot" as getting a high reward of a large set
examples, then the parameters found at the final step substituted into the
equation for the kind of model we're using give us will give us a function
which gets pretty good performance at the task we trained it for.

Two basic approaches ways to approach this problem are [supervised
learning][SL] and [reinforcement learning][RL]. The supervised learning
approach is equivalent to hiring a driving instructor to give advice in the
form "in situation X, do Y" and feedback in the form "you did $\hat{y}$ when
you should have done $y$!  That's great/OK/acceptable/terrible/catastrophic."
The reinforcement learning approach is letting the computer drive the car
randomly, crash a lot, and after each crash revisit the decisions in the
seconds leading up to the crash and ask, "what could have I have done
differently?"

Conclusion
----------

Next time, we'll start with [linear regression][MLFS1], followed by
[logistic regression][MLFS2] and some simple [neural networks][MLFS3].
As new articles are added, you can find them collected under the ["from scratch"][MLFS]
tag.

[FA]: https://en.wikipedia.org/wiki/Factor_analysis
[LTR]: https://en.wikipedia.org/wiki/Learning_to_rank
[NNZ]: https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464
[BTL]: https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model
[IRT]: https://en.wikipedia.org/wiki/Item_response_theory
[RM]: https://en.wikipedia.org/wiki/Rasch_model
[KNN]: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm
[RT]: https://en.wikipedia.org/wiki/R-tree
[DK]: https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect
[LP]: https://en.wikipedia.org/wiki/Lagrange_multiplier
[SVM]: https://en.wikipedia.org/wiki/Support-vector_machine
[VC]: https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory
[SL]: https://en.wikipedia.org/wiki/Supervised_learning
[USL]: https://en.wikipedia.org/wiki/Unsupervised_learning
[RL]: https://en.wikipedia.org/wiki/Reinforcement_learning

[MLFS]: /tags/from-scratch/
[MLFS1]: /post/ml-from-scratch-part-1-linear-regression/
[MLFS2]: /post/ml-from-scratch-part-2-logistic-regression/
[MLFS3]: /post/ml-from-scratch-part-3-backpropagation/

